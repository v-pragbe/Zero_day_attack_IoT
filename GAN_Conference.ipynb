{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1ac8ed5-969b-4fc5-ac53-2fbe1e80d96d",
   "metadata": {},
   "source": [
    "# Using Generative Adversarial Network to Create Zero-Day attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e8d2bec-1fcc-40eb-85ae-b985a7b6d74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ctgan import synthesizers\n",
    "from ctgan import CTGAN\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12da7eb4-3ebe-4da6-bae0-ab6291e49e2b",
   "metadata": {},
   "source": [
    "### Creating Zero Attacks from BoT Dataset Attack Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ac8e0ca-3e11-466c-be7e-e08fb4be74ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "Categorical columns: []\n",
      "Number of attack samples: 56844\n",
      "\n",
      "Training CTGAN on attack data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gen. (0.82) | Discrim. (-0.07): 100%|█████████| 100/100 [03:07<00:00,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTGAN training completed.\n",
      "\n",
      "Generating 1000 synthetic attack samples...\n",
      "Synthetic attack data generated successfully.\n",
      "Total attack samples after augmentation: 57844\n",
      "Number of normal samples: 13859\n",
      "Total samples in augmented dataset: 71703\n",
      "Augmented dataset shuffled.\n",
      "Augmented dataset saved successfully as\n",
      "\n",
      "Process completed successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the Dataset\n",
    "df = pd.read_csv(\"/Users/promisea/SAMKNN/NF-BoT-IoT/NF-BoT-IoT-DDoS.csv\")\n",
    "print(\"Dataset loaded successfully.\")\n",
    "\n",
    "# Data Preparation\n",
    "# -------------------\n",
    "# Drop irrelevant columns\n",
    "X = df.drop(['IPV4_SRC_ADDR', 'IPV4_DST_ADDR', 'Attack', 'Label'], axis=1)\n",
    "y = df['Label']\n",
    "\n",
    "# Encode labels if they are not numeric\n",
    "if y.dtype == 'object' or y.dtype.name == 'category':\n",
    "    y = y.astype('category').cat.codes\n",
    "\n",
    "# Combine features and labels for CTGAN\n",
    "data = X.copy()\n",
    "data['Label'] = y\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_columns = data.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "print(f\"Categorical columns: {categorical_columns}\")\n",
    "\n",
    "# Filter attack data (assuming Label=1 indicates attack)\n",
    "attack_data = data[data['Label'] == 1]\n",
    "print(f\"Number of attack samples: {len(attack_data)}\")\n",
    "\n",
    "# Train CTGAN\n",
    "# --------------\n",
    "ctgan = CTGAN(\n",
    "    epochs=100,          # Number of training epochs\n",
    "    batch_size=500,      # Batch size\n",
    "    verbose=True         # Verbose output during training\n",
    ")\n",
    "\n",
    "print(\"\\nTraining CTGAN on attack data...\")\n",
    "ctgan.fit(attack_data, discrete_columns=categorical_columns)\n",
    "print(\"CTGAN training completed.\")\n",
    "\n",
    "# Generate Synthetic Attack Data\n",
    "# ----------------------------------\n",
    "num_synthetic_samples = 1000  # Adjust as needed\n",
    "print(f\"\\nGenerating {num_synthetic_samples} synthetic attack samples...\")\n",
    "synthetic_attack_data = ctgan.sample(num_synthetic_samples)\n",
    "\n",
    "# Ensure 'Label' column exists and is set to 1\n",
    "synthetic_attack_data['Label'] = 1\n",
    "print(\"Synthetic attack data generated successfully.\")\n",
    "\n",
    "# Integrate Synthetic Data\n",
    "# ----------------------------\n",
    "# Combine real and synthetic attack data\n",
    "augmented_attack_data = pd.concat([attack_data, synthetic_attack_data], ignore_index=True)\n",
    "print(f\"Total attack samples after augmentation: {len(augmented_attack_data)}\")\n",
    "\n",
    "# Combine with normal data (Label=0)\n",
    "normal_data = data[data['Label'] == 0]\n",
    "print(f\"Number of normal samples: {len(normal_data)}\")\n",
    "\n",
    "# Create augmented dataset\n",
    "augmented_data = pd.concat([normal_data, augmented_attack_data], ignore_index=True)\n",
    "print(f\"Total samples in augmented dataset: {len(augmented_data)}\")\n",
    "\n",
    "# Shuffle the dataset\n",
    "augmented_data = augmented_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(\"Augmented dataset shuffled.\")\n",
    "\n",
    "# Save Augmented Data (Modified)\n",
    "# ----------------------------------\n",
    "# Instead of saving only the synthetic_attack_data, we now save the entire augmented_data\n",
    "augmented_data.to_csv(\"Augmented_NF-BoT-IoT-DDoS.csv\", index=False)\n",
    "print(\"Augmented dataset saved successfully as\")\n",
    "\n",
    "# Summary\n",
    "# -----------\n",
    "print(\"\\nProcess completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bccccc6-24d2-43d0-8862-e9443f31b435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "Categorical columns: []\n",
      "Number of attack samples: 56833\n",
      "\n",
      "Training CTGAN on attack data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gen. (0.61) | Discrim. (-0.28): 100%|█████████| 100/100 [02:45<00:00,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTGAN training completed.\n",
      "\n",
      "Generating 1000 synthetic attack samples...\n",
      "Synthetic attack data generated successfully.\n",
      "Total attack samples after augmentation: 57833\n",
      "Number of normal samples: 13859\n",
      "Total samples in augmented dataset: 71692\n",
      "Augmented dataset shuffled.\n",
      "Augmented dataset saved successfully \n",
      "\n",
      "Process completed successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the Dataset\n",
    "df = pd.read_csv(\"/Users/promisea/SAMKNN/NF-BoT-IoT/NF-BoT-IoT-DoS.csv\")\n",
    "print(\"Dataset loaded successfully.\")\n",
    "\n",
    "# Data Preparation\n",
    "# -------------------\n",
    "# Drop irrelevant columns\n",
    "X = df.drop(['IPV4_SRC_ADDR', 'IPV4_DST_ADDR', 'Attack', 'Label'], axis=1)\n",
    "y = df['Label']\n",
    "\n",
    "# Encode labels if they are not numeric\n",
    "if y.dtype == 'object' or y.dtype.name == 'category':\n",
    "    y = y.astype('category').cat.codes\n",
    "\n",
    "# Combine features and labels for CTGAN\n",
    "data = X.copy()\n",
    "data['Label'] = y\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_columns = data.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "print(f\"Categorical columns: {categorical_columns}\")\n",
    "\n",
    "# Filter attack data (assuming Label=1 indicates attack)\n",
    "attack_data = data[data['Label'] == 1]\n",
    "print(f\"Number of attack samples: {len(attack_data)}\")\n",
    "\n",
    "# Train CTGAN\n",
    "# --------------\n",
    "ctgan = CTGAN(\n",
    "    epochs=100,          # Number of training epochs\n",
    "    batch_size=500,      # Batch size\n",
    "    verbose=True         # Verbose output during training\n",
    ")\n",
    "\n",
    "print(\"\\nTraining CTGAN on attack data...\")\n",
    "ctgan.fit(attack_data, discrete_columns=categorical_columns)\n",
    "print(\"CTGAN training completed.\")\n",
    "\n",
    "# Generate Synthetic Attack Data\n",
    "# ----------------------------------\n",
    "num_synthetic_samples = 1000  # Adjust as needed\n",
    "print(f\"\\nGenerating {num_synthetic_samples} synthetic attack samples...\")\n",
    "synthetic_attack_data = ctgan.sample(num_synthetic_samples)\n",
    "\n",
    "# Ensure 'Label' column exists and is set to 1\n",
    "synthetic_attack_data['Label'] = 1\n",
    "print(\"Synthetic attack data generated successfully.\")\n",
    "\n",
    "# Integrate Synthetic Data\n",
    "# ----------------------------\n",
    "# Combine real and synthetic attack data\n",
    "augmented_attack_data = pd.concat([attack_data, synthetic_attack_data], ignore_index=True)\n",
    "print(f\"Total attack samples after augmentation: {len(augmented_attack_data)}\")\n",
    "\n",
    "# Combine with normal data (Label=0)\n",
    "normal_data = data[data['Label'] == 0]\n",
    "print(f\"Number of normal samples: {len(normal_data)}\")\n",
    "\n",
    "# Create augmented dataset\n",
    "augmented_data = pd.concat([normal_data, augmented_attack_data], ignore_index=True)\n",
    "print(f\"Total samples in augmented dataset: {len(augmented_data)}\")\n",
    "\n",
    "# Shuffle the dataset\n",
    "augmented_data = augmented_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(\"Augmented dataset shuffled.\")\n",
    "\n",
    "# Save Augmented Data (Modified)\n",
    "# ----------------------------------\n",
    "# Instead of saving only the synthetic_attack_data, we now save the entire augmented_data\n",
    "augmented_data.to_csv(\"Augmented_NF-BoT-IoT-DoS.csv\", index=False)\n",
    "print(\"Augmented dataset saved successfully \")\n",
    "\n",
    "# Summary\n",
    "# -----------\n",
    "print(\"\\nProcess completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5a9b58b-fb5f-4c6d-8d3d-41ce6868447b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "Categorical columns: []\n",
      "Number of attack samples: 470655\n",
      "\n",
      "Training CTGAN on attack data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gen. (0.12) | Discrim. (-0.01): 100%|█████████| 100/100 [22:28<00:00, 13.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTGAN training completed.\n",
      "\n",
      "Generating 1000 synthetic attack samples...\n",
      "Synthetic attack data generated successfully.\n",
      "Total attack samples after augmentation: 471655\n",
      "Number of normal samples: 13859\n",
      "Total samples in augmented dataset: 485514\n",
      "Augmented dataset shuffled.\n",
      "Augmented dataset saved successfully \n",
      "\n",
      "Process completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the Dataset\n",
    "df = pd.read_csv(\"/Users/promisea/SAMKNN/NF-BoT-IoT/NF-BoT-IoT-Recon.csv\")\n",
    "print(\"Dataset loaded successfully.\")\n",
    "\n",
    "# Data Preparation\n",
    "# -------------------\n",
    "# Drop irrelevant columns\n",
    "X = df.drop(['IPV4_SRC_ADDR', 'IPV4_DST_ADDR', 'Attack', 'Label'], axis=1)\n",
    "y = df['Label']\n",
    "\n",
    "# Encode labels if they are not numeric\n",
    "if y.dtype == 'object' or y.dtype.name == 'category':\n",
    "    y = y.astype('category').cat.codes\n",
    "\n",
    "# Combine features and labels for CTGAN\n",
    "data = X.copy()\n",
    "data['Label'] = y\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_columns = data.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "print(f\"Categorical columns: {categorical_columns}\")\n",
    "\n",
    "# Filter attack data (assuming Label=1 indicates attack)\n",
    "attack_data = data[data['Label'] == 1]\n",
    "print(f\"Number of attack samples: {len(attack_data)}\")\n",
    "\n",
    "# Train CTGAN\n",
    "# --------------\n",
    "ctgan = CTGAN(\n",
    "    epochs=100,          # Number of training epochs\n",
    "    batch_size=500,      # Batch size\n",
    "    verbose=True         # Verbose output during training\n",
    ")\n",
    "\n",
    "print(\"\\nTraining CTGAN on attack data...\")\n",
    "ctgan.fit(attack_data, discrete_columns=categorical_columns)\n",
    "print(\"CTGAN training completed.\")\n",
    "\n",
    "# Generate Synthetic Attack Data\n",
    "# ----------------------------------\n",
    "num_synthetic_samples = 1000  # Adjust as needed\n",
    "print(f\"\\nGenerating {num_synthetic_samples} synthetic attack samples...\")\n",
    "synthetic_attack_data = ctgan.sample(num_synthetic_samples)\n",
    "\n",
    "# Ensure 'Label' column exists and is set to 1\n",
    "synthetic_attack_data['Label'] = 1\n",
    "print(\"Synthetic attack data generated successfully.\")\n",
    "\n",
    "# Integrate Synthetic Data\n",
    "# ----------------------------\n",
    "# Combine real and synthetic attack data\n",
    "augmented_attack_data = pd.concat([attack_data, synthetic_attack_data], ignore_index=True)\n",
    "print(f\"Total attack samples after augmentation: {len(augmented_attack_data)}\")\n",
    "\n",
    "# Combine with normal data (Label=0)\n",
    "normal_data = data[data['Label'] == 0]\n",
    "print(f\"Number of normal samples: {len(normal_data)}\")\n",
    "\n",
    "# Create augmented dataset\n",
    "augmented_data = pd.concat([normal_data, augmented_attack_data], ignore_index=True)\n",
    "print(f\"Total samples in augmented dataset: {len(augmented_data)}\")\n",
    "\n",
    "# Shuffle the dataset\n",
    "augmented_data = augmented_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(\"Augmented dataset shuffled.\")\n",
    "\n",
    "# Save Augmented Data (Modified)\n",
    "# ----------------------------------\n",
    "# Instead of saving only the synthetic_attack_data, we now save the entire augmented_data\n",
    "augmented_data.to_csv(\"Augmented_NF-BoT-IoT-Recon.csv\", index=False)\n",
    "print(\"Augmented dataset saved successfully \")\n",
    "\n",
    "# Summary\n",
    "# -----------\n",
    "print(\"\\nProcess completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a2ae408-aa56-42ac-bfb3-94f67df8a531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "Categorical columns: []\n",
      "Number of attack samples: 1909\n",
      "\n",
      "Training CTGAN on attack data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gen. (-1.42) | Discrim. (-0.24): 100%|████████| 100/100 [00:04<00:00, 21.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTGAN training completed.\n",
      "\n",
      "Generating 1000 synthetic attack samples...\n",
      "Synthetic attack data generated successfully.\n",
      "Total attack samples after augmentation: 2909\n",
      "Number of normal samples: 13859\n",
      "Total samples in augmented dataset: 16768\n",
      "Augmented dataset shuffled.\n",
      "Augmented dataset saved successfully\n",
      "\n",
      "Process completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the Dataset\n",
    "df = pd.read_csv(\"/Users/promisea/SAMKNN/NF-BoT-IoT/NF-BoT-IoT-Theft.csv\")\n",
    "print(\"Dataset loaded successfully.\")\n",
    "\n",
    "# Data Preparation\n",
    "# -------------------\n",
    "# Drop irrelevant columns\n",
    "X = df.drop(['IPV4_SRC_ADDR', 'IPV4_DST_ADDR', 'Attack', 'Label'], axis=1)\n",
    "y = df['Label']\n",
    "\n",
    "# Encode labels if they are not numeric\n",
    "if y.dtype == 'object' or y.dtype.name == 'category':\n",
    "    y = y.astype('category').cat.codes\n",
    "\n",
    "# Combine features and labels for CTGAN\n",
    "data = X.copy()\n",
    "data['Label'] = y\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_columns = data.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "print(f\"Categorical columns: {categorical_columns}\")\n",
    "\n",
    "# Filter attack data (assuming Label=1 indicates attack)\n",
    "attack_data = data[data['Label'] == 1]\n",
    "print(f\"Number of attack samples: {len(attack_data)}\")\n",
    "\n",
    "# Train CTGAN\n",
    "# --------------\n",
    "ctgan = CTGAN(\n",
    "    epochs=100,          # Number of training epochs\n",
    "    batch_size=500,      # Batch size\n",
    "    verbose=True         # Verbose output during training\n",
    ")\n",
    "\n",
    "print(\"\\nTraining CTGAN on attack data...\")\n",
    "ctgan.fit(attack_data, discrete_columns=categorical_columns)\n",
    "print(\"CTGAN training completed.\")\n",
    "\n",
    "# Generate Synthetic Attack Data\n",
    "# ----------------------------------\n",
    "num_synthetic_samples = 1000  # Adjust as needed\n",
    "print(f\"\\nGenerating {num_synthetic_samples} synthetic attack samples...\")\n",
    "synthetic_attack_data = ctgan.sample(num_synthetic_samples)\n",
    "\n",
    "# Ensure 'Label' column exists and is set to 1\n",
    "synthetic_attack_data['Label'] = 1\n",
    "print(\"Synthetic attack data generated successfully.\")\n",
    "\n",
    "# Integrate Synthetic Data\n",
    "# ----------------------------\n",
    "# Combine real and synthetic attack data\n",
    "augmented_attack_data = pd.concat([attack_data, synthetic_attack_data], ignore_index=True)\n",
    "print(f\"Total attack samples after augmentation: {len(augmented_attack_data)}\")\n",
    "\n",
    "# Combine with normal data (Label=0)\n",
    "normal_data = data[data['Label'] == 0]\n",
    "print(f\"Number of normal samples: {len(normal_data)}\")\n",
    "\n",
    "# Create augmented dataset\n",
    "augmented_data = pd.concat([normal_data, augmented_attack_data], ignore_index=True)\n",
    "print(f\"Total samples in augmented dataset: {len(augmented_data)}\")\n",
    "\n",
    "# Shuffle the dataset\n",
    "augmented_data = augmented_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(\"Augmented dataset shuffled.\")\n",
    "\n",
    "# Save Augmented Data (Modified)\n",
    "# ----------------------------------\n",
    "# Instead of saving only the synthetic_attack_data, we now save the entire augmented_data\n",
    "augmented_data.to_csv(\"Augmented_NF-BoT-IoT-Theft.csv\", index=False)\n",
    "print(\"Augmented dataset saved successfully\")\n",
    "\n",
    "# Summary\n",
    "# -----------\n",
    "print(\"\\nProcess completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cf0b13-6400-4d0c-8192-3f827ad2e528",
   "metadata": {},
   "source": [
    "### Creating Zero Attacks from ToN IoT Dataset Attack Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e1c7adb-82f3-46c8-8acf-eb19f03fbf93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "Categorical columns: []\n",
      "Number of attack samples: 149621\n",
      "\n",
      "Training CTGAN on attack data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gen. (-0.42) | Discrim. (-0.12): 100%|████████| 100/100 [06:53<00:00,  4.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTGAN training completed.\n",
      "\n",
      "Generating 1000 synthetic attack samples...\n",
      "Synthetic attack data generated successfully.\n",
      "Total attack samples after augmentation: 150621\n",
      "Number of normal samples: 179647\n",
      "Total samples in augmented dataset: 330268\n",
      "Augmented dataset shuffled.\n",
      "Augmented dataset saved successfully\n",
      "\n",
      "Process completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the Dataset\n",
    "df = pd.read_csv(\"/Users/promisea/SAMKNN/NF-TON-IoT_v1/NF-ToN-IoT-DDoS.csv\")\n",
    "print(\"Dataset loaded successfully.\")\n",
    "\n",
    "# Data Preparation\n",
    "# -------------------\n",
    "# Drop irrelevant columns\n",
    "X = df.drop(['IPV4_SRC_ADDR', 'IPV4_DST_ADDR', 'Attack', 'Label'], axis=1)\n",
    "y = df['Label']\n",
    "\n",
    "# Encode labels if they are not numeric\n",
    "if y.dtype == 'object' or y.dtype.name == 'category':\n",
    "    y = y.astype('category').cat.codes\n",
    "\n",
    "# Combine features and labels for CTGAN\n",
    "data = X.copy()\n",
    "data['Label'] = y\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_columns = data.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "print(f\"Categorical columns: {categorical_columns}\")\n",
    "\n",
    "# Filter attack data (assuming Label=1 indicates attack)\n",
    "attack_data = data[data['Label'] == 1]\n",
    "print(f\"Number of attack samples: {len(attack_data)}\")\n",
    "\n",
    "# Train CTGAN\n",
    "# --------------\n",
    "ctgan = CTGAN(\n",
    "    epochs=100,          # Number of training epochs\n",
    "    batch_size=500,      # Batch size\n",
    "    verbose=True         # Verbose output during training\n",
    ")\n",
    "\n",
    "print(\"\\nTraining CTGAN on attack data...\")\n",
    "ctgan.fit(attack_data, discrete_columns=categorical_columns)\n",
    "print(\"CTGAN training completed.\")\n",
    "\n",
    "# Generate Synthetic Attack Data\n",
    "# ----------------------------------\n",
    "num_synthetic_samples = 1000  # Adjust as needed\n",
    "print(f\"\\nGenerating {num_synthetic_samples} synthetic attack samples...\")\n",
    "synthetic_attack_data = ctgan.sample(num_synthetic_samples)\n",
    "\n",
    "# Ensure 'Label' column exists and is set to 1\n",
    "synthetic_attack_data['Label'] = 1\n",
    "print(\"Synthetic attack data generated successfully.\")\n",
    "\n",
    "# Integrate Synthetic Data\n",
    "# ----------------------------\n",
    "# Combine real and synthetic attack data\n",
    "augmented_attack_data = pd.concat([attack_data, synthetic_attack_data], ignore_index=True)\n",
    "print(f\"Total attack samples after augmentation: {len(augmented_attack_data)}\")\n",
    "\n",
    "# Combine with normal data (Label=0)\n",
    "normal_data = data[data['Label'] == 0]\n",
    "print(f\"Number of normal samples: {len(normal_data)}\")\n",
    "\n",
    "# Create augmented dataset\n",
    "augmented_data = pd.concat([normal_data, augmented_attack_data], ignore_index=True)\n",
    "print(f\"Total samples in augmented dataset: {len(augmented_data)}\")\n",
    "\n",
    "# Shuffle the dataset\n",
    "augmented_data = augmented_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(\"Augmented dataset shuffled.\")\n",
    "\n",
    "# Save Augmented Data (Modified)\n",
    "# ----------------------------------\n",
    "# Instead of saving only the synthetic_attack_data, we now save the entire augmented_data\n",
    "augmented_data.to_csv(\"Augmented_NF-ToN-IoT-DDoS.csv\", index=False)\n",
    "print(\"Augmented dataset saved successfully\")\n",
    "\n",
    "# Summary\n",
    "# -----------\n",
    "print(\"\\nProcess completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c05ef991-1522-4ccb-97f1-d1e044b3a6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "Categorical columns: []\n",
      "Number of attack samples: 7533\n",
      "\n",
      "Training CTGAN on attack data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gen. (-1.39) | Discrim. (-0.13): 100%|████████| 100/100 [00:17<00:00,  5.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTGAN training completed.\n",
      "\n",
      "Generating 1000 synthetic attack samples...\n",
      "Synthetic attack data generated successfully.\n",
      "Total attack samples after augmentation: 8533\n",
      "Number of normal samples: 179647\n",
      "Total samples in augmented dataset: 188180\n",
      "Augmented dataset shuffled.\n",
      "Augmented dataset saved successfully\n",
      "\n",
      "Process completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the Dataset\n",
    "df = pd.read_csv(\"/Users/promisea/SAMKNN/NF-TON-IoT_v1/NF-ToN-IoT-DoS.csv\")\n",
    "print(\"Dataset loaded successfully.\")\n",
    "\n",
    "# Data Preparation\n",
    "# -------------------\n",
    "# Drop irrelevant columns\n",
    "X = df.drop(['IPV4_SRC_ADDR', 'IPV4_DST_ADDR', 'Attack', 'Label'], axis=1)\n",
    "y = df['Label']\n",
    "\n",
    "# Encode labels if they are not numeric\n",
    "if y.dtype == 'object' or y.dtype.name == 'category':\n",
    "    y = y.astype('category').cat.codes\n",
    "\n",
    "# Combine features and labels for CTGAN\n",
    "data = X.copy()\n",
    "data['Label'] = y\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_columns = data.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "print(f\"Categorical columns: {categorical_columns}\")\n",
    "\n",
    "# Filter attack data (assuming Label=1 indicates attack)\n",
    "attack_data = data[data['Label'] == 1]\n",
    "print(f\"Number of attack samples: {len(attack_data)}\")\n",
    "\n",
    "# Train CTGAN\n",
    "# --------------\n",
    "ctgan = CTGAN(\n",
    "    epochs=100,          # Number of training epochs\n",
    "    batch_size=500,      # Batch size\n",
    "    verbose=True         # Verbose output during training\n",
    ")\n",
    "\n",
    "print(\"\\nTraining CTGAN on attack data...\")\n",
    "ctgan.fit(attack_data, discrete_columns=categorical_columns)\n",
    "print(\"CTGAN training completed.\")\n",
    "\n",
    "# Generate Synthetic Attack Data\n",
    "# ----------------------------------\n",
    "num_synthetic_samples = 1000  # Adjust as needed\n",
    "print(f\"\\nGenerating {num_synthetic_samples} synthetic attack samples...\")\n",
    "synthetic_attack_data = ctgan.sample(num_synthetic_samples)\n",
    "\n",
    "# Ensure 'Label' column exists and is set to 1\n",
    "synthetic_attack_data['Label'] = 1\n",
    "print(\"Synthetic attack data generated successfully.\")\n",
    "\n",
    "# Integrate Synthetic Data\n",
    "# ----------------------------\n",
    "# Combine real and synthetic attack data\n",
    "augmented_attack_data = pd.concat([attack_data, synthetic_attack_data], ignore_index=True)\n",
    "print(f\"Total attack samples after augmentation: {len(augmented_attack_data)}\")\n",
    "\n",
    "# Combine with normal data (Label=0)\n",
    "normal_data = data[data['Label'] == 0]\n",
    "print(f\"Number of normal samples: {len(normal_data)}\")\n",
    "\n",
    "# Create augmented dataset\n",
    "augmented_data = pd.concat([normal_data, augmented_attack_data], ignore_index=True)\n",
    "print(f\"Total samples in augmented dataset: {len(augmented_data)}\")\n",
    "\n",
    "# Shuffle the dataset\n",
    "augmented_data = augmented_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(\"Augmented dataset shuffled.\")\n",
    "\n",
    "# Save Augmented Data (Modified)\n",
    "# ----------------------------------\n",
    "# Instead of saving only the synthetic_attack_data, we now save the entire augmented_data\n",
    "augmented_data.to_csv(\"Augmented_NF-ToN-IoT-DoS.csv\", index=False)\n",
    "print(\"Augmented dataset saved successfully\")\n",
    "\n",
    "# Summary\n",
    "# -----------\n",
    "print(\"\\nProcess completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c6b139b-8105-4622-bf76-d49e33b6ae7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "Categorical columns: []\n",
      "Number of attack samples: 680347\n",
      "\n",
      "Training CTGAN on attack data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gen. (-0.74) | Discrim. (0.14): 100%|█████████| 100/100 [30:01<00:00, 18.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTGAN training completed.\n",
      "\n",
      "Generating 1000 synthetic attack samples...\n",
      "Synthetic attack data generated successfully.\n",
      "Total attack samples after augmentation: 681347\n",
      "Number of normal samples: 179647\n",
      "Total samples in augmented dataset: 860994\n",
      "Augmented dataset shuffled.\n",
      "Augmented dataset saved successfully\n",
      "\n",
      "Process completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the Dataset\n",
    "df = pd.read_csv(\"/Users/promisea/SAMKNN/NF-TON-IoT_v1/NF-ToN-IoT-Injection.csv\")\n",
    "print(\"Dataset loaded successfully.\")\n",
    "\n",
    "# Data Preparation\n",
    "# -------------------\n",
    "# Drop irrelevant columns\n",
    "X = df.drop(['IPV4_SRC_ADDR', 'IPV4_DST_ADDR', 'Attack', 'Label'], axis=1)\n",
    "y = df['Label']\n",
    "\n",
    "# Encode labels if they are not numeric\n",
    "if y.dtype == 'object' or y.dtype.name == 'category':\n",
    "    y = y.astype('category').cat.codes\n",
    "\n",
    "# Combine features and labels for CTGAN\n",
    "data = X.copy()\n",
    "data['Label'] = y\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_columns = data.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "print(f\"Categorical columns: {categorical_columns}\")\n",
    "\n",
    "# Filter attack data (assuming Label=1 indicates attack)\n",
    "attack_data = data[data['Label'] == 1]\n",
    "print(f\"Number of attack samples: {len(attack_data)}\")\n",
    "\n",
    "# Train CTGAN\n",
    "# --------------\n",
    "ctgan = CTGAN(\n",
    "    epochs=100,          # Number of training epochs\n",
    "    batch_size=500,      # Batch size\n",
    "    verbose=True         # Verbose output during training\n",
    ")\n",
    "\n",
    "print(\"\\nTraining CTGAN on attack data...\")\n",
    "ctgan.fit(attack_data, discrete_columns=categorical_columns)\n",
    "print(\"CTGAN training completed.\")\n",
    "\n",
    "# Generate Synthetic Attack Data\n",
    "# ----------------------------------\n",
    "num_synthetic_samples = 1000  # Adjust as needed\n",
    "print(f\"\\nGenerating {num_synthetic_samples} synthetic attack samples...\")\n",
    "synthetic_attack_data = ctgan.sample(num_synthetic_samples)\n",
    "\n",
    "# Ensure 'Label' column exists and is set to 1\n",
    "synthetic_attack_data['Label'] = 1\n",
    "print(\"Synthetic attack data generated successfully.\")\n",
    "\n",
    "# Integrate Synthetic Data\n",
    "# ----------------------------\n",
    "# Combine real and synthetic attack data\n",
    "augmented_attack_data = pd.concat([attack_data, synthetic_attack_data], ignore_index=True)\n",
    "print(f\"Total attack samples after augmentation: {len(augmented_attack_data)}\")\n",
    "\n",
    "# Combine with normal data (Label=0)\n",
    "normal_data = data[data['Label'] == 0]\n",
    "print(f\"Number of normal samples: {len(normal_data)}\")\n",
    "\n",
    "# Create augmented dataset\n",
    "augmented_data = pd.concat([normal_data, augmented_attack_data], ignore_index=True)\n",
    "print(f\"Total samples in augmented dataset: {len(augmented_data)}\")\n",
    "\n",
    "# Shuffle the dataset\n",
    "augmented_data = augmented_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(\"Augmented dataset shuffled.\")\n",
    "\n",
    "# Save Augmented Data (Modified)\n",
    "# ----------------------------------\n",
    "# Instead of saving only the synthetic_attack_data, we now save the entire augmented_data\n",
    "augmented_data.to_csv(\"Augmented_NF-ToN-IoT-Injection.csv\", index=False)\n",
    "print(\"Augmented dataset saved successfully\")\n",
    "\n",
    "# Summary\n",
    "# -----------\n",
    "print(\"\\nProcess completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4a11822-39c2-46f7-a5b1-1f62001cdb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "Categorical columns: []\n",
      "Number of attack samples: 17389\n",
      "\n",
      "Training CTGAN on attack data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gen. (1.02) | Discrim. (-0.53): 100%|█████████| 100/100 [00:44<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTGAN training completed.\n",
      "\n",
      "Generating 1000 synthetic attack samples...\n",
      "Synthetic attack data generated successfully.\n",
      "Total attack samples after augmentation: 18389\n",
      "Number of normal samples: 179647\n",
      "Total samples in augmented dataset: 198036\n",
      "Augmented dataset shuffled.\n",
      "Augmented dataset saved successfully\n",
      "\n",
      "Process completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the Dataset\n",
    "df = pd.read_csv(\"/Users/promisea/SAMKNN/NF-TON-IoT_v1/NF-ToN-IoT-Malware.csv\")\n",
    "print(\"Dataset loaded successfully.\")\n",
    "\n",
    "# Data Preparation\n",
    "# -------------------\n",
    "# Drop irrelevant columns\n",
    "X = df.drop(['IPV4_SRC_ADDR', 'IPV4_DST_ADDR', 'Attack', 'Label'], axis=1)\n",
    "y = df['Label']\n",
    "\n",
    "# Encode labels if they are not numeric\n",
    "if y.dtype == 'object' or y.dtype.name == 'category':\n",
    "    y = y.astype('category').cat.codes\n",
    "\n",
    "# Combine features and labels for CTGAN\n",
    "data = X.copy()\n",
    "data['Label'] = y\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_columns = data.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "print(f\"Categorical columns: {categorical_columns}\")\n",
    "\n",
    "# Filter attack data (assuming Label=1 indicates attack)\n",
    "attack_data = data[data['Label'] == 1]\n",
    "print(f\"Number of attack samples: {len(attack_data)}\")\n",
    "\n",
    "# Train CTGAN\n",
    "# --------------\n",
    "ctgan = CTGAN(\n",
    "    epochs=100,          # Number of training epochs\n",
    "    batch_size=500,      # Batch size\n",
    "    verbose=True         # Verbose output during training\n",
    ")\n",
    "\n",
    "print(\"\\nTraining CTGAN on attack data...\")\n",
    "ctgan.fit(attack_data, discrete_columns=categorical_columns)\n",
    "print(\"CTGAN training completed.\")\n",
    "\n",
    "# Generate Synthetic Attack Data\n",
    "# ----------------------------------\n",
    "num_synthetic_samples = 1000  # Adjust as needed\n",
    "print(f\"\\nGenerating {num_synthetic_samples} synthetic attack samples...\")\n",
    "synthetic_attack_data = ctgan.sample(num_synthetic_samples)\n",
    "\n",
    "# Ensure 'Label' column exists and is set to 1\n",
    "synthetic_attack_data['Label'] = 1\n",
    "print(\"Synthetic attack data generated successfully.\")\n",
    "\n",
    "# Integrate Synthetic Data\n",
    "# ----------------------------\n",
    "# Combine real and synthetic attack data\n",
    "augmented_attack_data = pd.concat([attack_data, synthetic_attack_data], ignore_index=True)\n",
    "print(f\"Total attack samples after augmentation: {len(augmented_attack_data)}\")\n",
    "\n",
    "# Combine with normal data (Label=0)\n",
    "normal_data = data[data['Label'] == 0]\n",
    "print(f\"Number of normal samples: {len(normal_data)}\")\n",
    "\n",
    "# Create augmented dataset\n",
    "augmented_data = pd.concat([normal_data, augmented_attack_data], ignore_index=True)\n",
    "print(f\"Total samples in augmented dataset: {len(augmented_data)}\")\n",
    "\n",
    "# Shuffle the dataset\n",
    "augmented_data = augmented_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(\"Augmented dataset shuffled.\")\n",
    "\n",
    "# Save Augmented Data (Modified)\n",
    "# ----------------------------------\n",
    "# Instead of saving only the synthetic_attack_data, we now save the entire augmented_data\n",
    "augmented_data.to_csv(\"Augmented_NF-ToN-IoT-Malware.csv\", index=False)\n",
    "print(\"Augmented dataset saved successfully\")\n",
    "\n",
    "# Summary\n",
    "# -----------\n",
    "print(\"\\nProcess completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a6b7e2d-6633-455a-9663-4a09107838dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "Categorical columns: []\n",
      "Number of attack samples: 1215\n",
      "\n",
      "Training CTGAN on attack data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gen. (-1.09) | Discrim. (-0.19): 100%|████████| 100/100 [00:02<00:00, 34.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTGAN training completed.\n",
      "\n",
      "Generating 1000 synthetic attack samples...\n",
      "Synthetic attack data generated successfully.\n",
      "Total attack samples after augmentation: 2215\n",
      "Number of normal samples: 179647\n",
      "Total samples in augmented dataset: 181862\n",
      "Augmented dataset shuffled.\n",
      "Augmented dataset saved successfully\n",
      "\n",
      "Process completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the Dataset\n",
    "df = pd.read_csv(\"/Users/promisea/SAMKNN/NF-TON-IoT_v1/NF-ToN-IoT-MITM.csv\")\n",
    "print(\"Dataset loaded successfully.\")\n",
    "\n",
    "# Data Preparation\n",
    "# -------------------\n",
    "# Drop irrelevant columns\n",
    "X = df.drop(['IPV4_SRC_ADDR', 'IPV4_DST_ADDR', 'Attack', 'Label'], axis=1)\n",
    "y = df['Label']\n",
    "\n",
    "# Encode labels if they are not numeric\n",
    "if y.dtype == 'object' or y.dtype.name == 'category':\n",
    "    y = y.astype('category').cat.codes\n",
    "\n",
    "# Combine features and labels for CTGAN\n",
    "data = X.copy()\n",
    "data['Label'] = y\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_columns = data.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "print(f\"Categorical columns: {categorical_columns}\")\n",
    "\n",
    "# Filter attack data (assuming Label=1 indicates attack)\n",
    "attack_data = data[data['Label'] == 1]\n",
    "print(f\"Number of attack samples: {len(attack_data)}\")\n",
    "\n",
    "# Train CTGAN\n",
    "# --------------\n",
    "ctgan = CTGAN(\n",
    "    epochs=100,          # Number of training epochs\n",
    "    batch_size=500,      # Batch size\n",
    "    verbose=True         # Verbose output during training\n",
    ")\n",
    "\n",
    "print(\"\\nTraining CTGAN on attack data...\")\n",
    "ctgan.fit(attack_data, discrete_columns=categorical_columns)\n",
    "print(\"CTGAN training completed.\")\n",
    "\n",
    "# Generate Synthetic Attack Data\n",
    "# ----------------------------------\n",
    "num_synthetic_samples = 1000  # Adjust as needed\n",
    "print(f\"\\nGenerating {num_synthetic_samples} synthetic attack samples...\")\n",
    "synthetic_attack_data = ctgan.sample(num_synthetic_samples)\n",
    "\n",
    "# Ensure 'Label' column exists and is set to 1\n",
    "synthetic_attack_data['Label'] = 1\n",
    "print(\"Synthetic attack data generated successfully.\")\n",
    "\n",
    "# Integrate Synthetic Data\n",
    "# ----------------------------\n",
    "# Combine real and synthetic attack data\n",
    "augmented_attack_data = pd.concat([attack_data, synthetic_attack_data], ignore_index=True)\n",
    "print(f\"Total attack samples after augmentation: {len(augmented_attack_data)}\")\n",
    "\n",
    "# Combine with normal data (Label=0)\n",
    "normal_data = data[data['Label'] == 0]\n",
    "print(f\"Number of normal samples: {len(normal_data)}\")\n",
    "\n",
    "# Create augmented dataset\n",
    "augmented_data = pd.concat([normal_data, augmented_attack_data], ignore_index=True)\n",
    "print(f\"Total samples in augmented dataset: {len(augmented_data)}\")\n",
    "\n",
    "# Shuffle the dataset\n",
    "augmented_data = augmented_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(\"Augmented dataset shuffled.\")\n",
    "\n",
    "# Save Augmented Data (Modified)\n",
    "# ----------------------------------\n",
    "# Instead of saving only the synthetic_attack_data, we now save the entire augmented_data\n",
    "augmented_data.to_csv(\"Augmented_NF-ToN-IoT-MITM.csv\", index=False)\n",
    "print(\"Augmented dataset saved successfully\")\n",
    "\n",
    "# Summary\n",
    "# -----------\n",
    "print(\"\\nProcess completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a4cb8fa-07f7-4407-bd4e-7ef8f4d7f6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "Categorical columns: []\n",
      "Number of attack samples: 12823\n",
      "\n",
      "Training CTGAN on attack data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gen. (-0.16) | Discrim. (-0.19): 100%|████████| 100/100 [00:35<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTGAN training completed.\n",
      "\n",
      "Generating 1000 synthetic attack samples...\n",
      "Synthetic attack data generated successfully.\n",
      "Total attack samples after augmentation: 13823\n",
      "Number of normal samples: 179647\n",
      "Total samples in augmented dataset: 193470\n",
      "Augmented dataset shuffled.\n",
      "Augmented dataset saved successfully\n",
      "\n",
      "Process completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the Dataset\n",
    "df = pd.read_csv(\"/Users/promisea/SAMKNN/NF-TON-IoT_v1/NF-ToN-IoT-Scan.csv\")\n",
    "print(\"Dataset loaded successfully.\")\n",
    "\n",
    "# Data Preparation\n",
    "# -------------------\n",
    "# Drop irrelevant columns\n",
    "X = df.drop(['IPV4_SRC_ADDR', 'IPV4_DST_ADDR', 'Attack', 'Label'], axis=1)\n",
    "y = df['Label']\n",
    "\n",
    "# Encode labels if they are not numeric\n",
    "if y.dtype == 'object' or y.dtype.name == 'category':\n",
    "    y = y.astype('category').cat.codes\n",
    "\n",
    "# Combine features and labels for CTGAN\n",
    "data = X.copy()\n",
    "data['Label'] = y\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_columns = data.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "print(f\"Categorical columns: {categorical_columns}\")\n",
    "\n",
    "# Filter attack data (assuming Label=1 indicates attack)\n",
    "attack_data = data[data['Label'] == 1]\n",
    "print(f\"Number of attack samples: {len(attack_data)}\")\n",
    "\n",
    "# Train CTGAN\n",
    "# --------------\n",
    "ctgan = CTGAN(\n",
    "    epochs=100,          # Number of training epochs\n",
    "    batch_size=500,      # Batch size\n",
    "    verbose=True         # Verbose output during training\n",
    ")\n",
    "\n",
    "print(\"\\nTraining CTGAN on attack data...\")\n",
    "ctgan.fit(attack_data, discrete_columns=categorical_columns)\n",
    "print(\"CTGAN training completed.\")\n",
    "\n",
    "# Generate Synthetic Attack Data\n",
    "# ----------------------------------\n",
    "num_synthetic_samples = 1000  # Adjust as needed\n",
    "print(f\"\\nGenerating {num_synthetic_samples} synthetic attack samples...\")\n",
    "synthetic_attack_data = ctgan.sample(num_synthetic_samples)\n",
    "\n",
    "# Ensure 'Label' column exists and is set to 1\n",
    "synthetic_attack_data['Label'] = 1\n",
    "print(\"Synthetic attack data generated successfully.\")\n",
    "\n",
    "# Integrate Synthetic Data\n",
    "# ----------------------------\n",
    "# Combine real and synthetic attack data\n",
    "augmented_attack_data = pd.concat([attack_data, synthetic_attack_data], ignore_index=True)\n",
    "print(f\"Total attack samples after augmentation: {len(augmented_attack_data)}\")\n",
    "\n",
    "# Combine with normal data (Label=0)\n",
    "normal_data = data[data['Label'] == 0]\n",
    "print(f\"Number of normal samples: {len(normal_data)}\")\n",
    "\n",
    "# Create augmented dataset\n",
    "augmented_data = pd.concat([normal_data, augmented_attack_data], ignore_index=True)\n",
    "print(f\"Total samples in augmented dataset: {len(augmented_data)}\")\n",
    "\n",
    "# Shuffle the dataset\n",
    "augmented_data = augmented_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(\"Augmented dataset shuffled.\")\n",
    "\n",
    "# Save Augmented Data (Modified)\n",
    "# ----------------------------------\n",
    "# Instead of saving only the synthetic_attack_data, we now save the entire augmented_data\n",
    "augmented_data.to_csv(\"Augmented_NF-ToN-IoT-Scan.csv\", index=False)\n",
    "print(\"Augmented dataset saved successfully\")\n",
    "\n",
    "# Summary\n",
    "# -----------\n",
    "print(\"\\nProcess completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "tensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
